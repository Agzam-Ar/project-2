# Кодирование информации

## Количество информации
- **Определение**: Мера неопределенности, устраненной при получении сообщения
- **Принцип**: Чем менее вероятно событие, тем больше информации оно несет
- Количество информации можно определить через энтропию

---
## Энтропия (E)
- **Определение**: Мера неопределенности системы
- **Свойства**:
  - Чем больше вариантов и чем они равновероятнее → тем выше энтропия
  - Максимальна при равномерном распределении вероятностей
- **Формула**: 
$$
E = -\sum_{i=1}^{n} p_i \log_2 p_i
$$
Где $p_i$ - вероятность $i$-го события, $m$ - количество кодовых символов, $n$ - количество событий.

---
## Алфавитное кодирование

**Определение:**  Сопоставление каждому символу исходного алфавита A кодовой последовательности из алфавита B.

**Пример двоичного кодирования:**

| Символ | Код |
|--------|-----|
| A      | 00  |
| B      | 01  |
| C      | 10  |

> Примечание: Данный код не является префиксным и может вызывать неоднозначности при декодировании.

---
## Однозначное кодирование

**Определение:**  Способ кодирования, при котором любое закодированное сообщение может быть однозначно декодировано.

**Условия однозначности:**
- Использование **префиксных кодов** (код Хаффмана)
- Ни одно кодовое слово не является префиксом другого

**Пример префиксного кода:**

| Символ | Код |
|--------|-----|
| A      | 0   |
| B      | 10  |
| C      | 110 |
| D      | 111 |

---

## Проверь себя

### 1. Количество информации - это:
```quiz
- Мера длины сообщения  
+ Мера устраненной неопределенности  
- Скорость передачи данных  
- Размер алфавита  
```
### 2. Чем характеризуется энтропия?
```quiz
+ Мерой неопределенности системы  
- Количеством бит в сообщении  
- Скоростью обработки информации  
- Размером кодовой таблицы  
```
### 3. Алфавитное кодирование - это:
```quiz
- Сжатие данных без потерь
+ Сопоставление символов кодовым последовательностям
- Удаление избыточности в сообщении
- Шифрование информации
```
### 4. Какой код НЕ является однозначно декодируемым?
```quiz
- A=0, B=10, C=110
- A=1, B=01, C=001
+ A=0, B=01, C=11
- A=1, B=00, C=011
```
### 5. При каком условии энтропия максимальна?
```quiz
- Когда одно событие имеет вероятность 1
- Когда все события равновероятны
- Когда половина событий невозможна
- Когда вероятности образуют арифметическую прогрессию

```
### 6. Чем меньше вероятность события:
```quiz
- Тем меньше информации оно несет
+ Тем больше информации оно несет
- Тем ниже энтропия системы
- Тем короче должен быть его код
```


